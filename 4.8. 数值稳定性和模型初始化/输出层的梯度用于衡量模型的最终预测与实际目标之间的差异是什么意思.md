输出层的梯度用于衡量模型的最终预测与实际目标之间的差异，这句话的意思可以从以下几个方面来理解：

### 1. **模型预测与实际目标**
- **模型预测**: 在神经网络中，最后一层的输出（即预测值）是根据输入数据经过多层计算后得到的结果。例如，在一个分类任务中，输出层可能会生成每个类别的概率分布。
- **实际目标**: 这是模型在训练过程中要学习的真实标签或目标值。对于分类任务，实际目标通常是一个热编码向量（one-hot vector）；对于回归任务，实际目标是一个连续值。

### 2. **损失函数**
- **定义**: 损失函数（Loss Function）是用来量化模型预测与实际目标之间差异的数学函数。常见的损失函数有交叉熵损失（用于分类）和均方误差（用于回归）。
- **计算差异**: 损失函数计算模型的输出（预测值）与实际目标之间的差异，并返回一个数值，这个数值越小，表示模型的预测结果越接近实际目标。

### 3. **梯度的作用**
- **梯度计算**: 输出层的梯度 \( \mathbf{M}^{(K)} \) 是损失函数对输出的导数。它表示损失函数如何随着输出的变化而变化，即当输出值稍微改变时，损失函数的值会如何变化。
- **敏感度**: 这个梯度反映了模型对输出的敏感程度：如果梯度值较大，说明小的输出变化会导致损失函数有较大的变化，这意味着模型在该点需要更大幅度的调整；如果梯度值较小，说明输出与目标之间的差异较小，模型可以相对较小地调整权重。

### 4. **反向传播**
- **权重更新**: 在反向传播过程中，输出层的梯度会被用于更新神经网络的权重，以减少预测与实际目标之间的差异。通过反向传播，梯度会传递到前面的层，使得整个网络能够学习到更好的参数，从而提高模型的性能。

### 总结
输出层的梯度通过量化模型预测与实际目标之间的差异，帮助网络调整权重以减少这种差异，从而使模型的预测更加准确。这个过程是神经网络训练的核心，确保模型能够逐步学习到有效的特征和模式。